{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DISTRIBUTED GRAPHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import readfof\n",
    "from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "import scipy.spatial as SS\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/02 09:18:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "        .master(\"spark://master:7077\")\\\n",
    "        .appName(\"CosmoSparkApplication\")\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class graph:\n",
    "\n",
    "    def __init__(self, node_f, pos, sim_pars, glob_f, edge_idx, edge_f):\n",
    "        \n",
    "        self.node_f = node_f\n",
    "        self.pos = pos\n",
    "        self.sim_pars = sim_pars\n",
    "        self.glob_f = glob_f\n",
    "        self.edge_idx = edge_idx\n",
    "        self.edge_f = edge_f\n",
    "\n",
    "        self.boxsize = 1.e6 # Box size in comoving kpc/h \n",
    "\n",
    "        def plot3D(self, num, pars_file):\n",
    "            fig = plt.figure(figsize=(12, 12))\n",
    "            fontsize = 12\n",
    "\n",
    "            ax = fig.add_subplot(projection =\"3d\")\n",
    "\n",
    "            self.pos *= self.boxsize/1.e3   # show in Mpc\n",
    "\n",
    "            # Draw lines for each edge\n",
    "            for (src, dst) in self.edge_idx: #.t().tolist():\n",
    "\n",
    "                src = pos[int(src)].tolist()\n",
    "                dst = pos[int(dst)].tolist()\n",
    "\n",
    "                ax.plot([src[0], dst[0]], [src[1], dst[1]], zs=[src[2], dst[2]], linewidth=0.6, color='dimgrey')\n",
    "\n",
    "            # Plot nodes\n",
    "            mass_mean = np.mean(self.node_f)\n",
    "            for i,m in enumerate(self.node_f):\n",
    "                    ax.scatter(pos[i, 0], pos[i, 1], pos[i, 2], s=50*m*m/(mass_mean**2), zorder=1000, alpha=0.6, color = 'mediumpurple')\n",
    "\n",
    "            ax.xaxis.set_tick_params(labelsize=fontsize)\n",
    "            ax.yaxis.set_tick_params(labelsize=fontsize)\n",
    "            ax.zaxis.set_tick_params(labelsize=fontsize)\n",
    "\n",
    "            ax.set_xlabel('x (Mpc)', fontsize=16, labelpad=15)\n",
    "            ax.set_ylabel('y (Mpc)', fontsize=16, labelpad=15)\n",
    "            ax.set_zlabel('z (Mpc)', fontsize=16, labelpad=15)\n",
    "\n",
    "            rl = '$R_{link} = 0.2$'\n",
    "\n",
    "            ax.set_title(f'\\tGraph nÂ°{num}, Masses $\\\\geq 99.7$% percentile, {rl} Mpc \\t \\n \\n $\\\\Omega_m = {float(pars_file[0]):.3f}$ \\t $\\\\sigma_8 = {float(pars_file[1]):.3f}$', fontsize=20)\n",
    "\n",
    "            # fig.savefig(\"Plots/Graphs/graph_\"+num+\"_997.png\", bbox_inches='tight', pad_inches=0.6, dpi=400)\n",
    "            # plt.close(fig)\n",
    "\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "def read_cosmo_data(file_path):\n",
    "\n",
    "    # Read Fof\n",
    "    FoF = readfof.FoF_catalog(\n",
    "        file_path,           # simulation directory\n",
    "        2,                   # snapnum, indicating the redshift (z=1)\n",
    "        long_ids = False,\n",
    "        swap = False,\n",
    "        SFR = False,\n",
    "        read_IDs = False\n",
    "        )\n",
    "\n",
    "    return FoF\n",
    "\n",
    "# Get masses and positions\n",
    "def get_pos_mass(FoF):\n",
    "\n",
    "    pos = FoF.GroupPos/1e06             # Halo positions in Gpc/h \n",
    "    mass_raw = FoF.GroupMass * 1e10     # Halo masses in Msun/h\n",
    "\n",
    "    dim = pos.shape[0]\n",
    "    pos_mass_matrix = np.hstack([pos, mass_raw.reshape(dim,1)])\n",
    "\n",
    "    return pos_mass_matrix\n",
    "\n",
    "# Mass cut function\n",
    "def mass_filter(pos_mass_matrix):\n",
    "\n",
    "    mass = pos_mass_matrix[:,3]\n",
    "    pos = pos_mass_matrix[:,0:3]\n",
    "    cut = np.quantile(mass, 0.997)\n",
    "    mask = (mass >= cut)\n",
    "    mass_filtered = mass[mask]\n",
    "    pos_filtered = pos[mask]\n",
    "\n",
    "    dim = mass_filtered.shape[0]\n",
    "\n",
    "    pos_mass_matrix_filtered = np.hstack([pos_filtered, mass_filtered.reshape(dim,1)])\n",
    "\n",
    "    return pos_mass_matrix_filtered\n",
    "\n",
    "# Get KDTree\n",
    "def get_tree(pos_mass_matrix):\n",
    "\n",
    "    pos = pos = pos_mass_matrix[:,0:3]\n",
    "    kd_tree = SS.KDTree(pos, leafsize=16, boxsize=1.0001)\n",
    "\n",
    "    return kd_tree\n",
    "\n",
    "# Get edge indexes\n",
    "def get_edges(tree):\n",
    "\n",
    "    edge_idx = tree.query_pairs(r=0.2, output_type=\"ndarray\")\n",
    "\n",
    "    return edge_idx\n",
    "\n",
    "# Add reverse pairs\n",
    "def rev_pairs(edge_index_array):\n",
    "    reversepairs = edge_index_array[:, [1,0]]\n",
    "    edge_index_array_r = np.vstack([edge_index_array, reversepairs])\n",
    "    # make sure indexes are integers\n",
    "    return edge_index_array_r.astype(int)\n",
    "\n",
    "# Get edge features \n",
    "def get_edge_feat(joined_tuple):\n",
    "    # tuple: (positions_masses, indexes)\n",
    "    pos_mass = joined_tuple[0]\n",
    "    edg_idx = joined_tuple[1]\n",
    "    edg_idx = edg_idx.T\n",
    "    pos = pos_mass[:, 0:3]\n",
    "    # distance vector\n",
    "    row, col = edg_idx\n",
    "    diff = pos[row]-pos[col]\n",
    "\n",
    "    # boundary conditions\n",
    "    diff_bc = np.where(diff < -0.01, diff + 1.0, diff)\n",
    "    diff = np.where(diff > 0.01, diff - 1.0, diff_bc)\n",
    "\n",
    "    # distance = sqrt(dx^2+dy^2+dz^2)\n",
    "    dist = np.linalg.norm(diff, axis=1)\n",
    "\n",
    "    # centroid of halo catalogue (3d position of the centroid)\n",
    "    centroid = np.mean(pos,axis=0)\n",
    "\n",
    "    # distance between each point wrt the centroid\n",
    "    row = pos[row] - centroid\n",
    "    col = pos[col] - centroid\n",
    "\n",
    "    # boundary conditions\n",
    "    row_bc = np.where(row < -0.5, row + 1, row)\n",
    "    row = np.where(row > 0.5, row - 1, row_bc)\n",
    "\n",
    "    col_bc = np.where(col < -0.5, col + 1, col)\n",
    "    col = np.where(col > 0.5, col - 1, col_bc)\n",
    "\n",
    "    # normalizing\n",
    "    unitrow = row/(np.linalg.norm(row, axis = 1).reshape(-1, 1))  \n",
    "    unitcol = col/(np.linalg.norm(col, axis = 1).reshape(-1, 1))\n",
    "    unitdiff = diff/(dist.reshape(-1,1))    \n",
    "\n",
    "    # number of pairs\n",
    "    n_pairs = edg_idx.shape[1]\n",
    "\n",
    "    # get cosines\n",
    "    cos1 = np.array([np.dot(unitrow[i,:].T,unitcol[i,:]) for i in range(n_pairs)])\n",
    "    cos2 = np.array([np.dot(unitrow[i,:].T,unitdiff[i,:]) for i in range(n_pairs)])\n",
    "\n",
    "    # Normalize distance by linking radius\n",
    "    dist /= 0.2\n",
    "\n",
    "    # concatenate to get all edge attributes\n",
    "    edge_attr = np.concatenate([dist.reshape(-1,1), cos1.reshape(-1,1), cos2.reshape(-1,1)], axis=1)\n",
    "\n",
    "    return edge_attr\n",
    "\n",
    "# Get global features\n",
    "def get_glob_feat(pos_mass_matrix):\n",
    "    return math.log10(pos_mass_matrix.shape[0])\n",
    "\n",
    "# Build graph\n",
    "def get_graph(joined_tuple):\n",
    "    # tuple: (positions_masses, edge_idx, simulation_parameters, edge_attr, global_features)\n",
    "    pos_mass = joined_tuple[1][0]\n",
    "    edge_idx = joined_tuple[1][1]\n",
    "    sim_pars = joined_tuple[1][2]\n",
    "    edge_attr = joined_tuple[1][3]\n",
    "    glob_feat = joined_tuple[1][4]\n",
    "\n",
    "    masses = pos_mass[:,3]\n",
    "    pos = pos_mass[:, :3]\n",
    "\n",
    "    return graph(masses, pos, sim_pars, glob_feat, edge_idx, edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simulations parameters\n",
    "\n",
    "sim_pars_file = np.loadtxt(\"/mnt/cosmo_GNN/latin_hypercube_params.txt\", dtype=float)\n",
    "sim_pars_list = [(i, j) for i, j in enumerate(sim_pars_file)]\n",
    "sim_pars_file_rdd = sc.parallelize(sim_pars_list)\n",
    "sim_pars_file.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of simulation to use\n",
    "N_sims = 5\n",
    "\n",
    "# path list (key, value)\n",
    "path_list = [(i, \"/mnt/cosmo_GNN/Data/\"+str(i)) for i in range(N_sims)]\n",
    "\n",
    "# FoF RDD\n",
    "cosmo_rdd = sc.parallelize(path_list)\\\n",
    "            .mapValues(read_cosmo_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosmo_rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting positions and masses from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array RDD\n",
    "pos_mass_rdd = cosmo_rdd.mapValues(get_pos_mass)\n",
    "\n",
    "# filtering\n",
    "filtered_rdd = pos_mass_rdd.mapValues(mass_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KDTree RDD\n",
    "kdtree_rdd = filtered_rdd.mapValues(get_tree)\n",
    "\n",
    "# edge indexes RDD\n",
    "edge_idx_rdd = kdtree_rdd.mapValues(get_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding reverse pairs\n",
    "edge_idx_rdd_r = edge_idx_rdd.mapValues(rev_pairs)\n",
    "\n",
    "# join filtered arrays RDD and edge indexes RDD by key\n",
    "joined_rdd = filtered_rdd.join(edge_idx_rdd_r)\n",
    "\n",
    "# edge features (dist, cos1, cos2)\n",
    "edge_feat_rdd = joined_rdd.mapValues(get_edge_feat)\n",
    "\n",
    "# global features\n",
    "glob_feat_rdd = filtered_rdd.mapValues(get_glob_feat)\n",
    "\n",
    "# join position and masses, indexes, simulation parameters\n",
    "pos_mass_idx_simpar = joined_rdd.join(sim_pars_file_rdd)\\\n",
    "                                .map(lambda x: (x[0], (x[1][0][0], x[1][0][1], x[1][1])))\n",
    "\n",
    "# join edge attributes \n",
    "semicomplete_rdd = pos_mass_idx_simpar.join(edge_feat_rdd)\\\n",
    "                                      .map(lambda x: (x[0], (x[1][0][0], x[1][0][1], x[1][0][2], x[1][1])))\n",
    "\n",
    "# join all\n",
    "complete_rdd = semicomplete_rdd.join(glob_feat_rdd)\\\n",
    "                               .map(lambda x: (x[0], (x[1][0][0], x[1][0][1], x[1][0][2], x[1][0][3], x[1][1])))\n",
    "\n",
    "# graphs RDD\n",
    "graph_rdd = complete_rdd.map(get_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
